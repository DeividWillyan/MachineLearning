{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Realizados!\n"
     ]
    }
   ],
   "source": [
    "from goose import Goose\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "print(\"Imports Realizados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_naoLatin(string): \n",
    "    new_chars = []\n",
    "    for char in string:\n",
    "        if char == '\\n':\n",
    "            new_chars.append(' ')\n",
    "            continue\n",
    "        try:\n",
    "            if unicodedata.name(unicode(char)).startswith(('LATIN', 'SPACE')):\n",
    "                new_chars.append(char)\n",
    "        except:\n",
    "            continue\n",
    "    return ''.join(new_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_palavra(palavra):\n",
    "\n",
    "    # Unicode normalize transforma um caracter em seu equivalente em latin.\n",
    "    palavraSemAcento = palavra.lower()\n",
    "    try:\n",
    "        nfkd = unicodedata.normalize('NFKD', palavra)\n",
    "        palavraSemAcento = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
    "        palavraSemAcento = palavraSemAcento.lower()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Usa expressão regular para retornar a palavra apenas com números, letras e espaço\n",
    "    return re.sub('[^a-zA-Z0-9 \\\\\\]', '', palavraSemAcento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_stopwords(texto):\n",
    "    c = []\n",
    "    for i in stopwords.words(\"portuguese\"):\n",
    "        if len(i) > 1:\n",
    "            c.append(i)\n",
    "    saida = \"\"\n",
    "    for palavra in c:\n",
    "        saida = saida + \" \" + palavra\n",
    "\n",
    "    x = normalizar_palavra(saida)  \n",
    "    #print(x + \"\\n\")\n",
    "\n",
    "    p = \"\"\n",
    "    for _p in texto.split():\n",
    "        if _p not in x.split():\n",
    "            if len(_p) > 1:\n",
    "                p = p + _p + \" \"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_texto(texto):\n",
    "    texto = remover_naoLatin(texto)\n",
    "    texto = normalizar_palavra(texto)\n",
    "    return remover_stopwords(texto)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('out.csv')\n",
    "g = Goose()\n",
    "\n",
    "categorias = data['CATEGORIA']\n",
    "urls = data['URL']\n",
    "\n",
    "file = open(\"saida_maior.txt\", \"w\")\n",
    "for url, categoria in zip(urls, categorias):\n",
    "    artigo = g.extract(url=url)\n",
    "    #texto = artigo.meta_description\n",
    "    texto = artigo.cleaned_text\n",
    "    lista_palavras = processar_texto(texto)\n",
    "    if(len(lista_palavras) > 1):\n",
    "        file.write(categoria + \",\" + lista_palavras + '\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORIA</th>\n",
       "      <th>TEXTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noticia</td>\n",
       "      <td>rosinha deixou cadeia publica benfica zona nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noticia</td>\n",
       "      <td>brasilia policia federal apreendeu gabinete ae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noticia</td>\n",
       "      <td>superintendencia regional policia federal pf r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noticia</td>\n",
       "      <td>policias federal militar homens forcas armadas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noticia</td>\n",
       "      <td>termina nesta quintafeira feirao limpa nome se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORIA                                              TEXTO\n",
       "0   noticia  rosinha deixou cadeia publica benfica zona nor...\n",
       "1   noticia  brasilia policia federal apreendeu gabinete ae...\n",
       "2   noticia  superintendencia regional policia federal pf r...\n",
       "3   noticia  policias federal militar homens forcas armadas...\n",
       "4   noticia  termina nesta quintafeira feirao limpa nome se..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('./saida_maior.txt',sep=',',header=None, names=['CATEGORIA','TEXTO'])\n",
    "\n",
    "#df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar noticia em 1 e esporte em 0\n",
    "encoded_labels = df['CATEGORIA'].map(lambda x: 1 if x == 'noticia' else 0).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TEXTO'], encoded_labels)\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 100.0%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy score: {0:.1f}%.'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_test(url):\n",
    "    g = Goose()\n",
    "    artigo = g.extract(url=url)\n",
    "    texto = artigo.meta_description\n",
    "    lista_palavras = processar_texto(texto)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esporte\n"
     ]
    }
   ],
   "source": [
    "url = \"https://globoesporte.globo.com/futebol/noticia/bandeira-branca-apos-polemica-thiago-neves-diz-querer-jogar-ao-lado-de-luan.ghtml\"\n",
    "noticia = get_new_test(url)\n",
    "noticia_transformada = count_vector.transform([noticia])\n",
    "pred = naive_bayes.predict(noticia_transformada)\n",
    "\n",
    "print(\"noticia\" if pred == 1 else \"esporte\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
