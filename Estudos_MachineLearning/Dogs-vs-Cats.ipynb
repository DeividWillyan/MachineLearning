{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudos utilizando o dataset Dogs vc. Cats da competição oficial do Kaggle (https://www.kaggle.com/c/dogs-vs-cats).\n",
    "O Desafio é classificar de forma correta uma imagem de um cachorro ou um gato. Esta tarefa é fácil para um humano, porém é muito difícil para um computador. \n",
    "O Dataset contém 25 Mil imagens de dogs e cats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos deep learning com uma rede convolucional, construída com Keras e utilizando o tensorflow de backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos importando as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso dataset se encontra dentro da pasta -> datasets/dogs-vs-cats, iremos dividir o dataset em “original” que irá conter todo o dataset tanto de treino e teste, criamos também o diretório de trein e validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'datasets/dogs-vs-cats'\n",
    "\n",
    "original_dir = os.path.join(base_dir, 'original')\n",
    "original_train_dir = os.path.join(original_dir, 'train')\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "cats_train_dir = os.path.join(train_dir, 'cats')\n",
    "cats_validation_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "dogs_train_dir = os.path.join(train_dir, 'dogs')\n",
    "dogs_validation_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos os diretórios definidos no bloco anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not os.path.exists(train_dir)):\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(cats_train_dir)\n",
    "    os.mkdir(cats_validation_dir)\n",
    "    os.mkdir(dogs_train_dir)\n",
    "    os.mkdir(dogs_validation_dir)\n",
    "    print('Diretórios criados com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Bloco a baixo realiza o processo de copias para os diretórios que foram criados.\n",
    "\n",
    "Serão copiados 10k de imagens de dogs e 10k de cats do diretório \"original\" para o diretório de \"trein\".\n",
    "\n",
    "Serao copiados 2.5k de imagens de dos e 2.5k de imagens de cats para o diretório de \"validation\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.listdir(cats_train_dir) or  os.listdir(dogs_train_dir)):\n",
    "    def copy_images_to_folder(filename_pattern, start_range, stop_range, src_dir, dst_dir):\n",
    "        filenames = [filename_pattern.format(i) for i in range(start_range, stop_range)]\n",
    "        for filename in filenames:\n",
    "            src = os.path.join(src_dir, filename)\n",
    "            dst = os.path.join(dst_dir, filename)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "    copy_images_to_folder('cat.{}.jpg', 0, 10000, original_train_dir, cats_train_dir)\n",
    "    copy_images_to_folder('cat.{}.jpg', 10000, 12500, original_train_dir, cats_validation_dir)\n",
    "\n",
    "    copy_images_to_folder('dog.{}.jpg', 0, 10000, original_train_dir, dogs_train_dir)\n",
    "    copy_images_to_folder('dog.{}.jpg', 10000, 12500, original_train_dir, dogs_validation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo bloco nós definimos um batch_size de 20, este batch será o tamanho do lote que utilizaremos por iteração do modelo. Criamos o \"train_datagen\" e o \"validation_datagen\", eles utilizam a função ImageDataGenerator do keras, está função é responsável por gere lotes de dados de imagem do tensor com aumento de dados em tempo real. O próximo passo que o modelo faz é criar o \"train_generator\" que utiliza a função flow_from_directory, esta função aponta para o train_generator qual é o diretório que estão as imagens de treino e devolve as imagens em formatos de batch, neste caso cada batch de 20. O \"validation_generator\" faz a mesma coisa que o \"train_generator\", só que com dados de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(50,50), \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, \n",
    "                                                              target_size=(50,50), \n",
    "                                                              batch_size=batch_size, \n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Próximo passo é criar nosso modelo utilizando o \"Sequential()\" do keras, que é uma pilha linear de camadas.\n",
    "\n",
    "Vamos adicionando nossas camadas uma a uma conforme vamos criando nossa rede profunda. \n",
    "\n",
    "A Primeira Camada será do tipo Convolução 2D (Conv2D) o primeiro parâmetro deste layer é a dimensionalidade do espaço de saída, ou seja, o número de filtros de saída da convolução, o parâmetro \"kernel_size\" recebe a altura e a largura de janela de convolução 2D, o próximo parâmetro \"activation\" é a função de ativação que neste caso estamos utilizando relu e o último parâmetro \"input_shape\" recebe uma tupla informando qual a dimensionalidade da nossa imagem (50x50) nos informaremos (50,50,3) por conta da nossa imagem ser 50x50 e RGB.\n",
    "\n",
    "A Segunda Camada utiliza a função MaxPooling2D, que é responsável por realizar o agrupamento máximo para entradas 2D (imagens), o único parâmetro que estamos utilizando é \"pool_size\" este parâmetro especifica o tamanho da janela de agrupamento.\n",
    "\n",
    "Temos uma camada que utiliza a função \"Flatten()\", ela é responsável por realizar a “normalização” ou \"Achatamento/Aplaine\" das entradas dos dados para o formato que será utilizando na próxima camada.\n",
    "\n",
    "A última camada que utilizaremos no nosso modelo é a \"Dense\" que irá criar uma camada com 512 neurônios ocultos e seu segundo parâmetro é o \"activation\" que utiliza a função de ativação relu.\n",
    "\n",
    "No final o processo imprime uma representação resumida do modelo criado utilizando a função summary() do model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 307,393\n",
      "Trainable params: 307,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo do nosso processo agora é compilar o nosso modelo, usaremos para isso a função \"compile\" do nosso modelo, está função recebe como primeiro parâmetro \"loss\" que é a função de perda, utilizaremos \"binary_crossentropy\". O segundo parâmetro que passaremos para o compile será \"optimizer\" que é o parâmetro responsável por tentar otimizar o nosso modelo, usaremos \"rmsprop\" que é recomendado para redes neurais recorrentes. O último parâmetro que utilizaremos é o \"metrics\", será a métrica que utilizaremos para medir o quão bom está o nosso algoritmo, no nosso caso a métrica escolhida foi \"accuracy\".\n",
    "\n",
    "Agora iremos treinar o nosso modelo com lotes, isto garante uma melhor performance no processo de treino, utilizaremos o \"train_generator\" que criamos alguns blocos de códigos atrás, ele já está do formato que o nosso fit_generator necessita, o segundo parâmetro é o \"steps_pepr_epoch\" que é o número total de etapas, estamos utilizando o número total de dados de treino dividido pelo tamanho do nosso batch, o próximo parâmetro é \"epochs\" que será definido a quantidade de passos do nosso treinamento, o parâmetro \"validation_data\" recebe o os dados de validação que criamos anteriormente, e  parâmetro \"validation_steps\" definimos o número total de etapas de processo de validação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 0.6300 - acc: 0.6389 - val_loss: 0.5288 - val_acc: 0.7452\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 123s 123ms/step - loss: 0.5205 - acc: 0.7440 - val_loss: 0.4592 - val_acc: 0.7906\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 0.4576 - acc: 0.7866 - val_loss: 0.5075 - val_acc: 0.7424\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 0.4080 - acc: 0.8180 - val_loss: 0.4571 - val_acc: 0.7932\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.3751 - acc: 0.8350 - val_loss: 0.4045 - val_acc: 0.8238\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.3395 - acc: 0.8554 - val_loss: 0.4577 - val_acc: 0.8030\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.3215 - acc: 0.8641 - val_loss: 0.3767 - val_acc: 0.8330\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2958 - acc: 0.8758 - val_loss: 0.4030 - val_acc: 0.8304\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.2762 - acc: 0.8841 - val_loss: 0.3828 - val_acc: 0.8378\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.2624 - acc: 0.8931 - val_loss: 0.4487 - val_acc: 0.8340\n"
     ]
    }
   ],
   "source": [
    "if not (os.path.exists('modelo_treinado.model')):\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=20000/batch_size, \n",
    "                              epochs=10, \n",
    "                              validation_data=validation_generator, \n",
    "                              validation_steps=5000/batch_size)\n",
    "    \n",
    "    model.save('modelo_treinado.model')\n",
    "else:\n",
    "    model = tf.keras.models.load_model('modelo_treinado.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta celula para baixo, só estamos fazendo testes manuais em nosso modelo, para isto foi criado uma função para tratar as imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_img(img):\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.resize(img, (50,50))\n",
    "    return img.reshape(1,50,50,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predizer(img):\n",
    "    resultado = model.predict(tratar_img(img))\n",
    "    if(resultado > 0.5):\n",
    "        print(\"O Modelo preveu %s e era %s\" % (\"Cachorro\", img))\n",
    "    else:\n",
    "        print(\"O Modelo preveu %s e era %s\" % (\"Gato\", img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Modelo preveu Cachorro e era cachorro.jpg\n",
      "O Modelo preveu Cachorro e era cachorro1.jpg\n",
      "O Modelo preveu Cachorro e era cachorro2.jpg\n",
      "O Modelo preveu Gato e era gato.jpg\n",
      "O Modelo preveu Gato e era gato1.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir():\n",
    "    if(i.endswith('.jpg')):\n",
    "        #image = mpimg.imread(i)\n",
    "        #plt.imshow(image)\n",
    "        #plt.show()\n",
    "        predizer(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
