{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset com base https://www.kaggle.com/thedownhill/art-images-drawings-painting-sculpture-engraving/home\n",
    "\n",
    "Context: \n",
    "Dataset for classifying different styles of art. Main categories have been taken here<br>\n",
    "Content: \n",
    "5 kinds of data downloaded from google images, yandex images and this site:\n",
    "\n",
    "Drawings and watercolours<br>\n",
    "Works of painting<br>\n",
    "Sculpture<br>\n",
    "Graphic Art<br>\n",
    "Iconography (old Russian art)<br>\n",
    "\n",
    "\n",
    "Data is separated on training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './dataset'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'training_set')\n",
    "validation_dir = os.path.join(base_dir, 'validation_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redimensionando as imagens \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "os.mkdir(os.path.join(base_dir, 'training_set_convert'))\n",
    "os.mkdir(os.path.join(base_dir, 'validation_set_convert'))\n",
    "train_dir_convert = os.path.join(base_dir, 'training_set_convert')\n",
    "validation_dir_convert = os.path.join(base_dir, 'validation_set_convert')\n",
    "for i in labels:\n",
    "    os.mkdir(os.path.join(train_dir_convert, i))\n",
    "    os.mkdir(os.path.join(validation_dir_convert, i))\n",
    "\n",
    "for i in labels:\n",
    "    _dir = os.path.join(train_dir, i)\n",
    "    _dir_conv = os.path.join(train_dir_convert, i)\n",
    "    for x in os.listdir(_dir):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(_dir, x))\n",
    "            img = img.resize((28,28), Image.ANTIALIAS)\n",
    "            img.save(os.path.join(_dir_conv, x))\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels -> ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']\n",
      "\n",
      "No Conjunto de Treino:\n",
      "Label -> drawings, Tamanho -> 1107\n",
      "Label -> engraving, Tamanho -> 757\n",
      "Label -> iconography, Tamanho -> 2077\n",
      "Label -> painting, Tamanho -> 2042\n",
      "Label -> sculpture, Tamanho -> 1738\n",
      "\n",
      "No Conjunto de Teste:\n",
      "Label -> drawings, Tamanho -> 122\n",
      "Label -> engraving, Tamanho -> 84\n",
      "Label -> iconography, Tamanho -> 231\n",
      "Label -> painting, Tamanho -> 236\n",
      "Label -> sculpture, Tamanho -> 193\n",
      "\n",
      "[('painting', 236), ('sculpture', 193), ('engraving', 84), ('drawings', 122), ('iconography', 231)]\n",
      "[('painting', 2042), ('sculpture', 1738), ('engraving', 757), ('drawings', 1107), ('iconography', 2077)]\n"
     ]
    }
   ],
   "source": [
    "# adicionar rotulos as imagens.\n",
    "\n",
    "train_dir = train_dir_convert\n",
    "validation_dir_convert = validation_dir_convert\n",
    "\n",
    "# criando os rotulos\n",
    "labels = [x for x in os.listdir(train_dir)]\n",
    "print('labels -> %s\\n' % labels)\n",
    "\n",
    "# rotulo por image\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "print('No Conjunto de Treino:')\n",
    "for i in labels:\n",
    "    _dir = os.path.join(train_dir, i)\n",
    "    print('Label -> %s, Tamanho -> %s' % (i, len(os.listdir(_dir))))\n",
    "    \n",
    "print('\\nNo Conjunto de Teste:')\n",
    "for i in labels:\n",
    "    _dir = os.path.join(validation_dir, i)\n",
    "    print('Label -> %s, Tamanho -> %s' % (i, len(os.listdir(_dir))))\n",
    "\n",
    "for i in labels:\n",
    "    _dir = os.path.join(train_dir, i)\n",
    "    for x in range(len(os.listdir(_dir))):\n",
    "        y_train.append(i)\n",
    "    \n",
    "for i in labels:\n",
    "    _dir = os.path.join(validation_dir, i)\n",
    "    for x in range(len(os.listdir(_dir))):\n",
    "        y_test.append(i)\n",
    "\n",
    "\n",
    "def frequecia(lista):\n",
    "    d = Counter(lista)\n",
    "    n, m = d.keys(), d.values()\n",
    "    print([i for i in zip(n,m)])  \n",
    "\n",
    "print('')\n",
    "frequecia(y_test)\n",
    "frequecia(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7721 images belonging to 5 classes.\n",
      "Found 866 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(28,28), \n",
    "                                                    batch_size=20, \n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, \n",
    "                                                              target_size=(28,28), \n",
    "                                                              batch_size=20, \n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "def generate_data_generator_for_two_images(X1, X2, Y):\n",
    "    genX1 = train_datagen.flow(X1,Y, seed=7)\n",
    "    genX2 = train_datagen.flow(X2, seed=7)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2 .next()\n",
    "            yield [X1i[0], X2i ], X1i[1]\n",
    "\n",
    "train_datagen = generate_data_generator_for_two_images(28,28,3)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 28, 28, 3)         99        \n",
      "=================================================================\n",
      "Total params: 227\n",
      "Trainable params: 227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(28,28,3)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_16 to have 4 dimensions, but got array with shape (20, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b7a8683c6014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     validation_steps=866/20)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1211\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_16 to have 4 dimensions, but got array with shape (20, 5)"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=7820/20, \n",
    "    epochs=10, \n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=866/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
